const { chatModel, freeModel } = require("@config/gemini");
const { KnowledgeDocument } = require("@models");
const NodeCache = require("node-cache");
const SessionManager = require("@utils/sessionManager");

/**
 * Gemini AI Service v·ªõi RAG (Retrieval-Augmented Generation)
 *
 * LOGIC HO·∫†T ƒê·ªòNG:
 *
 * 1. CH∆ØA TRAIN (KB r·ªóng):
 *    - AI c√≥ th·ªÉ tr·∫£ l·ªùi B·∫§T C·ª® G√å (kh√¥ng ch·∫∑n scope)
 *    - D√πng ƒë·ªÉ demo kh·∫£ nƒÉng AI "lung tung" khi ch∆∞a ƒë∆∞·ª£c train
 *
 * 2. ƒê√É TRAIN (c√≥ KB):
 *    - AI CH·ªà tr·∫£ l·ªùi trong ph·∫°m vi d·ªØ li·ªáu ƒë∆∞·ª£c train
 *    - Ch·∫∑n c√°c c√¢u h·ªèi nh·∫°y c·∫£m (ch√≠nh tr·ªã, y t·∫ø, ph√°p lu·∫≠t...)
 *    - N·∫øu c√¢u h·ªèi kh√¥ng li√™n quan ƒë·∫øn KB ‚Üí t·ª´ ch·ªëi tr·∫£ l·ªùi
 *
 * 3. SERVICE X√ìA D·ªÆ LI·ªÜU:
 *    - clearAllDocuments(): X√≥a to√†n b·ªô KB ‚Üí AI quay l·∫°i tr·∫°ng th√°i "ch∆∞a train"
 *    - clearExcelTraining(): X√≥a d·ªØ li·ªáu import t·ª´ Excel
 */
class GeminiService {
  constructor() {
    // Cache response v·ªõi TTL t·ª± ƒë·ªông cleanup
    this.responseCache = new NodeCache({
      stdTTL: 3600, // 1 hour
      checkperiod: 600, // Check every 10 mins ƒë·ªÉ cleanup expired
      maxKeys: 1000, // Gi·ªõi h·∫°n 1000 entries
      useClones: false, // Performance optimization
    });

    // Cache tr·∫°ng th√°i KB ƒë·ªÉ tr√°nh query li√™n t·ª•c
    this._kbStatusCache = {
      hasKnowledge: null,
      lastCheck: 0,
      ttl: 60000, // 1 ph√∫t
    };
  }

  /**
   * Ki·ªÉm tra xem KB c√≥ d·ªØ li·ªáu kh√¥ng (c√≥ cache)
   * @returns {Promise<boolean>}
   */
  async hasKnowledgeBase() {
    const now = Date.now();

    // Check cache
    if (
      this._kbStatusCache.hasKnowledge !== null &&
      now - this._kbStatusCache.lastCheck < this._kbStatusCache.ttl
    ) {
      return this._kbStatusCache.hasKnowledge;
    }

    // Query DB
    const count = await KnowledgeDocument.countDocuments({ isActive: true });
    this._kbStatusCache.hasKnowledge = count > 0;
    this._kbStatusCache.lastCheck = now;

    return this._kbStatusCache.hasKnowledge;
  }

  /**
   * Build context t·ª´ Knowledge Base
   *
   * @param {string} userQuery - C√¢u h·ªèi c·ªßa user
   * @returns {string|null} - Context string ho·∫∑c null n·∫øu kh√¥ng t√¨m th·∫•y KB
   */
  async buildContext(userQuery) {
    // Sanitize user input ƒë·ªÉ tr√°nh NoSQL injection v√† regex DoS
    const sanitizedQuery = userQuery
      .replace(/[${}]/g, "") // Remove MongoDB operators
      .replace(/[\\^$.*+?()[\]|]/g, " ") // Remove regex special chars
      .slice(0, 500) // Limit length ƒë·ªÉ tr√°nh DoS
      .trim();

    // Search Knowledge Base (MongoDB Text Search)
    // Text index ƒë√£ ƒë∆∞·ª£c t·∫°o tr√™n: title (weight 10), tags (5), content (1)
    const knowledgeDocs = await KnowledgeDocument.find(
      {
        $text: { $search: sanitizedQuery },
        isActive: true,
      },
      {
        score: { $meta: "textScore" },
      }
    )
      .sort({ score: { $meta: "textScore" }, priority: -1 })
      .limit(5); // TƒÉng l√™n 5 ƒë·ªÉ c√≥ context phong ph√∫ h∆°n

    if (knowledgeDocs.length === 0) {
      return null;
    }

    // Build context string t·ª´ c√°c KB docs t√¨m ƒë∆∞·ª£c
    const contextParts = [];

    knowledgeDocs.forEach((doc) => {
      contextParts.push(`[${doc.category.toUpperCase()}] ${doc.title}`);
      contextParts.push(doc.content);
      contextParts.push("---");
    });

    return contextParts.join("\n");
  }

  /**
   * Validate c√¢u h·ªèi c√≥ trong ph·∫°m vi cho ph√©p kh√¥ng
   * CH·ªà CH·∫†Y KHI ƒê√É C√ì KB (ƒë√£ train)
   */
  isInScope(userQuery) {
    const outOfScopePatterns = [
      /ch√≠nh tr·ªã|t·ªïng th·ªëng|b·∫ßu c·ª≠|ƒë·∫£ng|qu·ªëc h·ªôi/i,
      /thu·ªëc|b·ªánh|y t·∫ø|ƒëi·ªÅu tr·ªã|kh√°m b·ªánh|ung th∆∞|covid/i,
      /lu·∫≠t|ph√°p lu·∫≠t|ki·ªán|t√≤a √°n|h√¨nh s·ª±|d√¢n s·ª±/i,
      /t√¥n gi√°o|ph·∫≠t gi√°o|c√¥ng gi√°o|h·ªìi gi√°o|ch√∫a/i,
      /hack|crack|ph·∫ßn m·ªÅm l·∫≠u|virus|malware/i,
      /c√°ch l√†m bom|v≈© kh√≠|ma t√∫y|c·∫ßn sa/i,
      /khi√™u d√¢m|sex|18\+|ng∆∞·ªùi l·ªõn/i,
    ];

    return !outOfScopePatterns.some((pattern) => pattern.test(userQuery));
  }

  /**
   * Chat with Gemini AI
   *
   * LOGIC:
   * - Ch∆∞a train (KB r·ªóng): AI tr·∫£ l·ªùi t·ª± do, kh√¥ng ch·∫∑n scope
   * - ƒê√£ train (c√≥ KB): AI ch·ªâ tr·∫£ l·ªùi trong ph·∫°m vi KB, ch·∫∑n c√¢u h·ªèi nh·∫°y c·∫£m
   */
  async chat(userMessage, { sessionId, history = [] }) {
    try {
      // 1. Ki·ªÉm tra KB c√≥ d·ªØ li·ªáu kh√¥ng
      const hasKB = await this.hasKnowledgeBase();

      // 2. N·∫æU ƒê√É C√ì KB ‚Üí Ch·∫∑n c√¢u h·ªèi nh·∫°y c·∫£m
      if (hasKB && !this.isInScope(userMessage)) {
        return {
          response:
            "Xin l·ªói, t√¥i ch·ªâ c√≥ th·ªÉ h·ªó tr·ª£ v·ªÅ s·∫£n ph·∫©m gi√†y v√† d·ªãch v·ª• c·ªßa shop. B·∫°n c√≥ c√¢u h·ªèi n√†o kh√°c kh√¥ng? üòä",
          outOfScope: true,
          trained: true,
        };
      }

      // 3. Build context t·ª´ Knowledge Base
      const context = await this.buildContext(userMessage);

      // 4. Check cache
      const contextHash = context ? "trained" : "untrained";
      const cacheKey = `${contextHash}_${userMessage
        .toLowerCase()
        .slice(0, 100)}`;
      const cached = this.responseCache.get(cacheKey);
      if (cached) {
        return { response: cached, cached: true, trained: hasKB };
      }

      // 5. Prepare chat history
      const chatHistory = history.map((msg) => ({
        role: msg.role === "user" ? "user" : "model",
        parts: [{ text: msg.text }],
      }));

      // 6. Ch·ªçn model d·ª±a tr√™n tr·∫°ng th√°i KB
      // - hasKB = true: D√πng chatModel (c√≥ system instruction, gi·ªõi h·∫°n scope)
      // - hasKB = false: D√πng freeModel (kh√¥ng system instruction, tr·∫£ l·ªùi t·ª± do)
      const model = hasKB ? chatModel : freeModel;
      const chat = model.startChat({
        history: chatHistory,
      });

      // 7. Build prompt d·ª±a tr√™n tr·∫°ng th√°i KB
      let fullPrompt;

      if (hasKB && context) {
        // ƒê√É TRAIN + T√åM TH·∫§Y CONTEXT ‚Üí Tr·∫£ l·ªùi d·ª±a tr√™n KB
        fullPrompt = `B·∫°n l√† tr·ª£ l√Ω AI c·ªßa shop gi√†y. H√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa kh√°ch h√†ng D·ª∞A TR√äN TH√îNG TIN SAU:

üìö KI·∫æN TH·ª®C C·ª¶A SHOP:
${context}

‚ö†Ô∏è QUY T·∫ÆC:
- CH·ªà tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p ·ªü tr√™n
- N·∫øu th√¥ng tin kh√¥ng c√≥ trong ki·∫øn th·ª©c, h√£y n√≥i "T√¥i kh√¥ng c√≥ th√¥ng tin v·ªÅ v·∫•n ƒë·ªÅ n√†y. Vui l√≤ng li√™n h·ªá hotline 1900 xxxx ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n."
- Tr·∫£ l·ªùi ng·∫Øn g·ªçn, th√¢n thi·ªán, b·∫±ng ti·∫øng Vi·ªát
- Kh√¥ng b·ªãa th√¥ng tin

‚ùì C√ÇU H·ªéI KH√ÅCH H√ÄNG: ${userMessage}`;
      } else if (hasKB && !context) {
        // ƒê√É TRAIN + KH√îNG T√åM TH·∫§Y CONTEXT ‚Üí T·ª´ ch·ªëi l·ªãch s·ª±
        return {
          response:
            "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi c·ªßa b·∫°n trong h·ªá th·ªëng. Vui l√≤ng li√™n h·ªá hotline 1900 xxxx ho·∫∑c chat v·ªõi nh√¢n vi√™n h·ªó tr·ª£ ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt h∆°n nh√©! üôè",
          noContext: true,
          trained: true,
        };
      } else {
        // CH∆ØA TRAIN ‚Üí AI tr·∫£ l·ªùi t·ª± do (demo mode)
        fullPrompt = `B·∫°n l√† m·ªôt AI assistant th√¥ng minh. H√£y tr·∫£ l·ªùi c√¢u h·ªèi sau m·ªôt c√°ch h·ªØu √≠ch v√† ch√≠nh x√°c b·∫±ng ti·∫øng Vi·ªát:

${userMessage}

L∆∞u √Ω: Tr·∫£ l·ªùi ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu.`;
      }

      // 8. G·ª≠i t·ªõi Gemini v·ªõi timeout
      const GEMINI_TIMEOUT = 30000;
      const result = await Promise.race([
        chat.sendMessage(fullPrompt),
        new Promise((_, reject) =>
          setTimeout(
            () => reject(new Error("Gemini API timeout sau 30 gi√¢y")),
            GEMINI_TIMEOUT
          )
        ),
      ]);
      const response = result.response.text();

      // 9. Cache response
      this.responseCache.set(cacheKey, response);

      return {
        response,
        trained: hasKB,
        hasContext: !!context,
      };
    } catch (error) {
      console.error("[GEMINI] Chat error:", error);
      return this._handleError(error);
    }
  }

  /**
   * X·ª≠ l√Ω l·ªói t·ª´ Gemini API
   * @private
   */
  _handleError(error) {
    const errorStatus = error.status || error.statusCode;

    if (errorStatus === 429) {
      const quotaExhausted = error.message?.includes("limit: 0");
      const retryMatch = error.message?.match(/retry in (\d+)/i);
      const retrySeconds = retryMatch ? retryMatch[1] : "v√†i";

      if (quotaExhausted) {
        return {
          response:
            "H·ªá th·ªëng AI ƒë√£ h·∫øt l∆∞·ª£t s·ª≠ d·ª•ng h√¥m nay. Vui l√≤ng chat v·ªõi nh√¢n vi√™n h·ªó tr·ª£ ho·∫∑c g·ªçi hotline 1900 xxxx ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n nh√©!",
          error: true,
          rateLimited: true,
          quotaExhausted: true,
        };
      }

      return {
        response: `AI ƒëang b·∫≠n, vui l√≤ng th·ª≠ l·∫°i sau ${retrySeconds} gi√¢y ho·∫∑c chat v·ªõi nh√¢n vi√™n h·ªó tr·ª£ nh√©!`,
        error: true,
        rateLimited: true,
      };
    }

    if (errorStatus === 404) {
      return {
        response:
          "üîß H·ªá th·ªëng AI ƒëang b·∫£o tr√¨. Vui l√≤ng chat v·ªõi nh√¢n vi√™n h·ªó tr·ª£ ho·∫∑c g·ªçi hotline 1900 xxxx.",
        error: true,
      };
    }

    return {
      response:
        "Xin l·ªói, t√¥i ƒëang g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t. Vui l√≤ng chat v·ªõi nh√¢n vi√™n h·ªó tr·ª£ ho·∫∑c g·ªçi hotline 1900 xxxx. üôè",
      error: true,
      errorDetails: error.message,
    };
  }

  /**
   * L·∫•y tr·∫°ng th√°i training c·ªßa AI
   */
  async getTrainingStatus() {
    const hasKB = await this.hasKnowledgeBase();
    const totalDocs = await KnowledgeDocument.countDocuments({
      isActive: true,
    });

    return {
      trained: hasKB,
      totalDocuments: totalDocs,
      description: hasKB
        ? `AI ƒë√£ ƒë∆∞·ª£c train v·ªõi ${totalDocs} documents. Ch·ªâ tr·∫£ l·ªùi trong ph·∫°m vi d·ªØ li·ªáu.`
        : "AI CH∆ØA ƒë∆∞·ª£c train. C√≥ th·ªÉ tr·∫£ l·ªùi b·∫•t c·ª© g√¨ (demo mode).",
    };
  }

  /**
   * Clear cache (khi update/delete knowledge base)
   */
  clearCache() {
    this.responseCache.flushAll();
    // Reset KB status cache ƒë·ªÉ force recheck
    this._kbStatusCache.hasKnowledge = null;
    this._kbStatusCache.lastCheck = 0;

    return {
      message: "Cache cleared successfully",
      stats: this.responseCache.getStats(),
    };
  }

  /**
   * Get cache statistics
   */
  getCacheStats() {
    return this.responseCache.getStats();
  }

  /**
   * Validate v√† generate session ID
   * @private
   */
  _validateAndGenerateSessionId(clientSessionId, clientIp) {
    let sessionId = clientSessionId;

    if (sessionId) {
      if (!SessionManager.validateSessionId(sessionId)) {
        sessionId = SessionManager.generateSessionId(clientIp);
      } else if (SessionManager.isExpired(sessionId, 24 * 60 * 60 * 1000)) {
        sessionId = SessionManager.generateSessionId(clientIp);
      }
    } else {
      sessionId = SessionManager.generateSessionId(clientIp);
    }

    return sessionId;
  }

  /**
   * Chat with validation (wrapper for controller)
   */
  async chatWithValidation(
    message,
    { clientSessionId, clientIp, history = [] }
  ) {
    const sessionId = this._validateAndGenerateSessionId(
      clientSessionId,
      clientIp
    );

    const result = await this.chat(message, {
      sessionId,
      history,
    });

    return {
      ...result,
      sessionId,
    };
  }
}

module.exports = new GeminiService();
